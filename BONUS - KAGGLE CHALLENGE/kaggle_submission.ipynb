{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94635,"databundleVersionId":13121456,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Jigsaw - Agile Community Rules Classification\n# Advanced BERT Fine-tuning Solution\n# Target: 0.925+ AUC\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport warnings\nimport sys\nimport gc\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nwarnings.filterwarnings('ignore')\nprint(\"Starting Advanced BERT Solution...\", flush=True)\nprint(f\"PyTorch version: {torch.__version__}\", flush=True)\nprint(f\"CUDA available: {torch.cuda.is_available()}\", flush=True)\n\n# ============================================================================\n# 1. LOAD DATA\n# ============================================================================\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"1. LOADING DATA\", flush=True)\nprint(\"=\"*80, flush=True)\n\ntrain_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/train.csv')\ntest_df = pd.read_csv('/kaggle/input/jigsaw-agile-community-rules/test.csv')\n\nprint(f\"Train shape: {train_df.shape}\", flush=True)\nprint(f\"Test shape: {test_df.shape}\", flush=True)\nprint(f\"Unique rules in train: {train_df['rule'].nunique()}\", flush=True)\nprint(f\"Target distribution: {train_df['rule_violation'].value_counts().to_dict()}\", flush=True)\n\n# ============================================================================\n# 2. CREATE FORMATTED TEXT INPUT\n# ============================================================================\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"2. PREPARING STRUCTURED INPUT\", flush=True)\nprint(\"=\"*80, flush=True)\n\ndef create_input_text(row):\n    \"\"\"Create structured input that includes rule context and examples\"\"\"\n    text = f\"\"\"Rule: {row['rule']}\n\nExamples that VIOLATE this rule:\n- {row['positive_example_1']}\n- {row['positive_example_2']}\n\nExamples that DO NOT violate this rule:\n- {row['negative_example_1']}\n- {row['negative_example_2']}\n\nComment to evaluate: {row['body']}\"\"\"\n    \n    return text\n\ndef create_simple_input(row):\n    \"\"\"Simpler format for faster processing\"\"\"\n    return f\"Rule: {row['rule']} | Positive: {row['positive_example_1']} {row['positive_example_2']} | Negative: {row['negative_example_1']} {row['negative_example_2']} | Comment: {row['body']}\"\n\n# Create both formats\nprint(\"Creating structured inputs...\", flush=True)\ntrain_df['input_text'] = train_df.apply(create_simple_input, axis=1)\ntest_df['input_text'] = test_df.apply(create_simple_input, axis=1)\n\nprint(f\"Sample input:\\n{train_df['input_text'].iloc[0][:200]}...\", flush=True)\n\n# ============================================================================\n# 3. TRANSFORMER SETUP\n# ============================================================================\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"3. SETTING UP TRANSFORMER MODEL\", flush=True)\nprint(\"=\"*80, flush=True)\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom torch.utils.data import Dataset\n\n# Choose model - using DeBERTa-v3 for best performance\nMODEL_NAME = 'microsoft/deberta-v3-small'  # Fast and effective\n# Alternative: 'microsoft/deberta-v3-base' for better performance but slower\n# Alternative: 'bert-base-uncased' for baseline\n\nprint(f\"Loading model: {MODEL_NAME}\", flush=True)\n\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n    print(\"âœ“ Tokenizer loaded\", flush=True)\nexcept Exception as e:\n    print(f\"Error loading tokenizer: {e}\", flush=True)\n    print(\"Falling back to bert-base-uncased\", flush=True)\n    MODEL_NAME = 'bert-base-uncased'\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\n# ============================================================================\n# 4. CREATE DATASET\n# ============================================================================\n\nclass RuleViolationDataset(Dataset):\n    def __init__(self, texts, labels=None, tokenizer=None, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        \n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        \n        item = {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten()\n        }\n        \n        if self.labels is not None:\n            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n        \n        return item\n\nprint(\"Creating datasets...\", flush=True)\n\n# Tokenize to check lengths\nsample_lengths = []\nfor text in train_df['input_text'].head(100):\n    tokens = tokenizer(text, truncation=False)\n    sample_lengths.append(len(tokens['input_ids']))\n\nprint(f\"Token length stats - Mean: {np.mean(sample_lengths):.0f}, Max: {np.max(sample_lengths):.0f}\", flush=True)\n\n# Set max length based on data\nMAX_LENGTH = min(512, int(np.percentile(sample_lengths, 95)) + 50)\nprint(f\"Using max_length: {MAX_LENGTH}\", flush=True)\n\n# ============================================================================\n# 5. TRAINING WITH CROSS-VALIDATION\n# ============================================================================\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"4. TRAINING WITH CROSS-VALIDATION\", flush=True)\nprint(\"=\"*80, flush=True)\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = torch.softmax(torch.tensor(predictions), dim=-1)[:, 1].numpy()\n    auc = roc_auc_score(labels, predictions)\n    return {'auc': auc}\n\n# Training configuration\nEPOCHS = 3\nBATCH_SIZE = 8\nLEARNING_RATE = 2e-5\nN_FOLDS = 5\n\nskf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\noof_predictions = np.zeros(len(train_df))\ntest_predictions = np.zeros(len(test_df))\nfold_scores = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['rule_violation'])):\n    print(f\"\\n{'='*80}\", flush=True)\n    print(f\"FOLD {fold + 1}/{N_FOLDS}\", flush=True)\n    print(f\"{'='*80}\", flush=True)\n    \n    # Prepare data\n    train_texts = train_df.iloc[train_idx]['input_text'].values\n    train_labels = train_df.iloc[train_idx]['rule_violation'].values\n    val_texts = train_df.iloc[val_idx]['input_text'].values\n    val_labels = train_df.iloc[val_idx]['rule_violation'].values\n    \n    train_dataset = RuleViolationDataset(train_texts, train_labels, tokenizer, MAX_LENGTH)\n    val_dataset = RuleViolationDataset(val_texts, val_labels, tokenizer, MAX_LENGTH)\n    \n    # Initialize model\n    model = AutoModelForSequenceClassification.from_pretrained(\n        MODEL_NAME,\n        num_labels=2,\n        problem_type=\"single_label_classification\"\n    )\n    \n    # Training arguments\n    training_args = TrainingArguments(\n        output_dir=f'./results_fold_{fold}',\n        num_train_epochs=EPOCHS,\n        per_device_train_batch_size=BATCH_SIZE,\n        per_device_eval_batch_size=BATCH_SIZE * 2,\n        learning_rate=LEARNING_RATE,\n        warmup_steps=100,\n        weight_decay=0.01,\n        logging_dir=f'./logs_fold_{fold}',\n        logging_steps=50,\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        load_best_model_at_end=True,\n        metric_for_best_model=\"auc\",\n        greater_is_better=True,\n        report_to=\"none\",\n        fp16=torch.cuda.is_available(),\n    )\n    \n    # Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics,\n    )\n    \n    # Train\n    print(f\"Training fold {fold + 1}...\", flush=True)\n    trainer.train()\n    \n    # Validation predictions\n    val_pred = trainer.predict(val_dataset)\n    val_probs = torch.softmax(torch.tensor(val_pred.predictions), dim=-1)[:, 1].numpy()\n    val_auc = roc_auc_score(val_labels, val_probs)\n    \n    print(f\"Fold {fold + 1} Validation AUC: {val_auc:.4f}\", flush=True)\n    fold_scores.append(val_auc)\n    oof_predictions[val_idx] = val_probs\n    \n    # Test predictions\n    test_dataset = RuleViolationDataset(test_df['input_text'].values, None, tokenizer, MAX_LENGTH)\n    test_pred = trainer.predict(test_dataset)\n    test_probs = torch.softmax(torch.tensor(test_pred.predictions), dim=-1)[:, 1].numpy()\n    test_predictions += test_probs / N_FOLDS\n    \n    # Clean up\n    del model, trainer, train_dataset, val_dataset, test_dataset\n    gc.collect()\n    torch.cuda.empty_cache()\n\n# ============================================================================\n# 6. RESULTS AND SUBMISSION\n# ============================================================================\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"5. CROSS-VALIDATION RESULTS\", flush=True)\nprint(\"=\"*80, flush=True)\n\noverall_auc = roc_auc_score(train_df['rule_violation'], oof_predictions)\nprint(f\"\\nFold AUC scores: {[f'{s:.4f}' for s in fold_scores]}\", flush=True)\nprint(f\"Mean Fold AUC: {np.mean(fold_scores):.4f} (+/- {np.std(fold_scores):.4f})\", flush=True)\nprint(f\"Overall OOF AUC: {overall_auc:.4f}\", flush=True)\n\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"6. CREATING SUBMISSION\", flush=True)\nprint(\"=\"*80, flush=True)\n\nsubmission = pd.DataFrame({\n    'row_id': test_df['row_id'].values,\n    'rule_violation': np.clip(test_predictions, 0.001, 0.999)\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(f\"\\nâœ“ Submission created successfully!\", flush=True)\nprint(f\"\\nPrediction statistics:\", flush=True)\nprint(f\"  Min: {submission['rule_violation'].min():.4f}\", flush=True)\nprint(f\"  Max: {submission['rule_violation'].max():.4f}\", flush=True)\nprint(f\"  Mean: {submission['rule_violation'].mean():.4f}\", flush=True)\nprint(f\"  Median: {submission['rule_violation'].median():.4f}\", flush=True)\n\nprint(\"\\nFirst 10 predictions:\", flush=True)\nprint(submission.head(10), flush=True)\n\nprint(\"\\n\" + \"=\"*80, flush=True)\nprint(\"TRAINING COMPLETE!\", flush=True)\nprint(f\"Expected Public LB Score: ~{overall_auc:.4f}\", flush=True)\nprint(\"=\"*80, flush=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-03T19:44:29.995449Z","iopub.execute_input":"2025-10-03T19:44:29.996019Z","iopub.status.idle":"2025-10-03T19:47:05.811978Z","shell.execute_reply.started":"2025-10-03T19:44:29.995992Z","shell.execute_reply":"2025-10-03T19:47:05.810304Z"}},"outputs":[],"execution_count":null}]}